{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it a chocolate bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: Kaggle requires phone verification to use the internet or a GPU. If you haven't done that yet, the cell below will fail\n",
    "#    This code is only here to check that your internet is enabled. It doesn't do anything else.\n",
    "#    Here's a help thread on getting your phone number verified: https://www.kaggle.com/product-feedback/135367\n",
    "\n",
    "import socket,warnings\n",
    "try:\n",
    "    socket.setdefaulttimeout(1)\n",
    "    socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))\n",
    "except socket.error as ex: raise Exception(\"STOP: No internet. Click '>|' in top right and set 'Internet' switch to on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a good idea to ensure you're running the latest version of any libraries you need.\n",
    "# `!pip install -Uqq <libraries>` upgrades to the latest version of <libraries>\n",
    "# NB: You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\n",
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "if iskaggle:\n",
    "    !pip install -Uqq fastai duckduckgo_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download images of chocolate bar and other candys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you already have duckduckgo_search installed\n",
    "!pip install -Uqq duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import ddg_images\n",
    "from fastcore.all import *\n",
    "\n",
    "def search_images(term, max_images=30):\n",
    "    print(f\"Searching for '{term}'\")\n",
    "    return L(ddg_images(term, max_results=max_images)).itemgot('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by searching for a chocolate bar photo and seeing what kind of result we get. We'll start by getting URLs from a search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n",
    "#    If you get a JSON error, just try running it again (it may take a couple of tries).\n",
    "urls = search_images('chocolate bar photos', max_images=1)\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then download a URL and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdownload import download_url\n",
    "dest = 'chocolate_bar.jpg'\n",
    "download_url(urls[0], dest, show_progress=False)\n",
    "\n",
    "from fastai.vision.all import *\n",
    "im = Image.open(dest)\n",
    "im.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same with \"lollipop photos\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(search_images('lollipop photos', max_images=1)[0], 'lollipop.jpg', show_progress=False)\n",
    "Image.open('lollipop.jpg').to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our searches seem to be giving reasonable results, so let's grab a few examples of each of \"chocolate bar\" and \"lollipop\" photos, and save each group of photos to a different folder (I'm also trying to grab a range of lighting conditions here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = 'chocolate_bar','lollipop'\n",
    "path = Path('chocolate_or_lollipop')\n",
    "from time import sleep\n",
    "\n",
    "for o in searches:\n",
    "    dest = (path/o)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    download_images(dest, urls=search_images(f'{o} photo'))\n",
    "    sleep(10)  # Pause between searches to avoid over-loading server\n",
    "    download_images(dest, urls=search_images(f'{o} chocolate photo'))\n",
    "    sleep(10)\n",
    "    download_images(dest, urls=search_images(f'{o} candy photo'))\n",
    "    sleep(10)\n",
    "    download_images(dest, urls=search_images(f'{o} shade photo'))\n",
    "    sleep(10)\n",
    "    resize_images(path/o, max_size=400, dest=path/o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some photos might not download correctly which could cause our model training to fail, so we'll remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=[Resize(192, method='squish')]\n",
    ").dataloaders(path, bs=32)\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what each of the `DataBlock` parameters means:\n",
    "\n",
    "blocks=(ImageBlock, CategoryBlock),\n",
    "\n",
    "The inputs to our model are images, and the outputs are categories (in this case, \"rainy_weather\" or \"sunny_weather\").\n",
    "\n",
    "get_items=get_image_files, \n",
    "\n",
    "To find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n",
    "\n",
    "splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "\n",
    "Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
    "\n",
    "get_y=parent_label,\n",
    "\n",
    "The labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be rainy_weather or sunny_weather).\n",
    "\n",
    "item_tfms=[Resize(192, method='squish')]\n",
    "\n",
    "Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).\n",
    "\n",
    "Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n",
    "\n",
    "`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n",
    "\n",
    "\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it's important, check out the [free fast.ai course](https://course.fast.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use our model (and build your own!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our model thinks about that chocolate bar we downloaded at the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_chocolate_bar,_,probs = learn.predict(PILImage.create('chocolate_bar.jpg'))\n",
    "print(f\"This is a: {is_chocolate_bar}.\")\n",
    "print(f\"Probability it's a chocolate bar: {probs[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
